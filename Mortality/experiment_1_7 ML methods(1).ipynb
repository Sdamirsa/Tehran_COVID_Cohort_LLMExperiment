{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa37cf1a",
   "metadata": {
    "id": "aa37cf1a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04828757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3e4a4",
   "metadata": {},
   "source": [
    "# Train and Test sets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02a26e93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaKAvFOG3Pei",
    "outputId": "c5184fab-cf27-4718-a625-d56b4148d302"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "\n",
    "# Set the search parameters\n",
    "filename = \"3.xlsx\"\n",
    "search_path = '/content/drive/My Drive'\n",
    "\n",
    "# Search for the file\n",
    "for root, dirs, files in os.walk(search_path):\n",
    "    if filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41093536",
   "metadata": {
    "id": "p1Bjnwy73ZTk"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the XLSX file into a DataFrame\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe0678",
   "metadata": {},
   "source": [
    "## Training set (imputing and normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e641ad",
   "metadata": {
    "id": "78e641ad"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5aa2e9cb",
   "metadata": {
    "id": "5aa2e9cb"
   },
   "outputs": [],
   "source": [
    "# ooutcome columns: 1.are Outcome_InhospitalMortality 2.TM_S_Intubation  3.Outcome_ICUadmission  4.TM_S_Dialysis\n",
    "df = df.dropna(subset=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea49b803",
   "metadata": {
    "id": "ea49b803"
   },
   "outputs": [],
   "source": [
    "#inja oomadim va external validation ro freeze kardim\n",
    "df_internal_validation = df[df['Patient_Hospital']!=\"Hospital2\"]\n",
    "df_external_validation = df[df['Patient_Hospital']==\"Hospital2\"]\n",
    "\n",
    "\n",
    "df_internal_validation = df_internal_validation.drop(columns=['Patient_Hospital'])\n",
    "df_external_validation = df_external_validation.drop(columns=['Patient_Hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8424ee1",
   "metadata": {
    "id": "c8424ee1"
   },
   "outputs": [],
   "source": [
    "#df.to_excel(\"excluding NAN.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31d91627",
   "metadata": {
    "id": "31d91627"
   },
   "outputs": [],
   "source": [
    "#inja train test split kardim va target variable ro jodakardim\n",
    "# Define features (X) and target variable (y)\n",
    "X = df_internal_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y  = df_internal_validation[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "# Perform the train-test split (adjust the test_size as needed)\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57c05e69",
   "metadata": {
    "id": "57c05e69"
   },
   "outputs": [],
   "source": [
    "#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\n",
    "cat_col=[]\n",
    "num_col=[]\n",
    "for i in range(len(X_train.columns)):\n",
    "    if i <=52:\n",
    "        cat_col.append(X_train.columns[i])\n",
    "    else:\n",
    "        num_col.append(X_train.columns[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b87b9bee",
   "metadata": {
    "id": "8f573066"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "X_train_array  =X_train.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed = imputer.fit_transform(X_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8386bb00",
   "metadata": {
    "id": "8386bb00"
   },
   "outputs": [],
   "source": [
    "df_imputed = pd.DataFrame(imputed)\n",
    "df_imputed.columns=pd.DataFrame(X_train).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25a108af",
   "metadata": {
    "id": "25a108af"
   },
   "outputs": [],
   "source": [
    "for i in cat_col:\n",
    "    df_imputed[[i]] = df_imputed[[i]].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4fb058d",
   "metadata": {
    "id": "f4fb058d"
   },
   "outputs": [],
   "source": [
    "df_imputed.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbadc812",
   "metadata": {
    "id": "fbadc812"
   },
   "outputs": [],
   "source": [
    "#miaim x , y ro be ham michaboonim ta betonim normilize konim\n",
    "df_before_normalize = pd.concat([df_imputed , y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8982e9dc",
   "metadata": {
    "id": "8982e9dc"
   },
   "outputs": [],
   "source": [
    "arr_tain =df_imputed.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "869a57d6",
   "metadata": {
    "id": "869a57d6"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_normalize = transform.fit_transform(arr_tain)\n",
    "df_normalize =pd.DataFrame(df_normalize)\n",
    "df_normalize.columns = df_imputed.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "099db9ad",
   "metadata": {
    "id": "099db9ad"
   },
   "outputs": [],
   "source": [
    "X_train = df_normalize\n",
    "y_train = df_before_normalize[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13dbcf8",
   "metadata": {
    "id": "e13dbcf8"
   },
   "source": [
    "## Test set (imputing and normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf48fe2a",
   "metadata": {
    "id": "cf48fe2a"
   },
   "outputs": [],
   "source": [
    "#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\n",
    "cat_col=[]\n",
    "num_col=[]\n",
    "for i in range(len(X_test.columns)):\n",
    "    if i <=52:\n",
    "        cat_col.append(X_test.columns[i])\n",
    "    else:\n",
    "        num_col.append(X_test.columns[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "275b6806",
   "metadata": {
    "id": "275b6806"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "X_test_array  =X_test.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed_test = imputer.fit_transform(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b197071",
   "metadata": {
    "id": "9b197071"
   },
   "outputs": [],
   "source": [
    "df_imputed_test = pd.DataFrame(imputed_test)\n",
    "df_imputed_test.columns=pd.DataFrame(X_test).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60d64f56",
   "metadata": {
    "id": "60d64f56"
   },
   "outputs": [],
   "source": [
    "for i in cat_col:\n",
    "    df_imputed_test[[i]] = df_imputed_test[[i]].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70070982",
   "metadata": {
    "id": "70070982"
   },
   "outputs": [],
   "source": [
    "df_imputed_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23494689",
   "metadata": {
    "id": "23494689"
   },
   "outputs": [],
   "source": [
    "#miaim x , y ro be ham michaboonim ta betonim normilize konim\n",
    "df_test_before_normalize = pd.concat([df_imputed_test , y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c574350",
   "metadata": {
    "id": "4c574350"
   },
   "outputs": [],
   "source": [
    "arr =df_test_before_normalize.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "601f755f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "601f755f",
    "outputId": "4baa5416-fcaf-4560-8521-8c1fefd8bb4b"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_test_normalize = transform.fit_transform(arr)\n",
    "df_test_normalize =pd.DataFrame(df_test_normalize)\n",
    "df_test_normalize.columns = df_internal_validation.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29ec76da",
   "metadata": {
    "id": "29ec76da"
   },
   "outputs": [],
   "source": [
    "X_test = df_test_normalize.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_test = df_test_before_normalize[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac69b28",
   "metadata": {
    "id": "6ac69b28"
   },
   "source": [
    ">>>Now dataset is cleaned and normalized "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bfd27f",
   "metadata": {
    "id": "65bfd27f"
   },
   "source": [
    "# experimenting different models on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03126cba",
   "metadata": {
    "id": "03126cba"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d8e654f8",
   "metadata": {
    "id": "d8e654f8"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f4e9e",
   "metadata": {
    "id": "249f4e9e"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9b8b780",
   "metadata": {
    "id": "a9b8b780"
   },
   "outputs": [],
   "source": [
    "\n",
    "#remember to consider x_test and y_test for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12beb341",
   "metadata": {
    "id": "12beb341"
   },
   "outputs": [],
   "source": [
    "y_train_Outcome_InhospitalMortality = np.array(y_train['Outcome_InhospitalMortality'].tolist())\n",
    "y_test_Outcome_InhospitalMortality = np.array(y_test['Outcome_InhospitalMortality'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a73cea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "def logistic_regression_classifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    parameters_lr = {}\n",
    "\n",
    "\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_predicted_Mortality_lr = best_classifier_lr.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_lr)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_lr)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_lr)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_lr)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_lr)\n",
    "\n",
    "\n",
    "    Logistic_Regression = {}\n",
    "    Logistic_Regression[\"accuracy\"] = accuracy\n",
    "    Logistic_Regression[\"precision\"] = precision\n",
    "    Logistic_Regression[\"recall\"] = recall\n",
    "    Logistic_Regression[\"specificity\"] = specificity\n",
    "    Logistic_Regression[\"f1\"] = f1\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_lr\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ff100",
   "metadata": {
    "id": "d43ff100"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "77900b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_svm(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    svm_classifier = svm.SVC(random_state=1234)\n",
    "\n",
    "\n",
    "    parameters_svm = {}\n",
    "\n",
    "\n",
    "    grid_search_svm = GridSearchCV(\n",
    "        estimator=svm_classifier,\n",
    "        param_grid=parameters_svm,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "   \n",
    "    svm_cv = grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    " \n",
    "    best_classifier_svm = svm_cv.best_estimator_\n",
    "\n",
    "\n",
    "    y_predicted_Mortality_svm = best_classifier_svm.predict(X_test)\n",
    "\n",
    "   \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_svm)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_svm)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_svm)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_svm)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_svm)\n",
    "\n",
    "    svm_results = {}\n",
    "    svm_results[\"accuracy\"] = accuracy\n",
    "    svm_results[\"precision\"] = precision\n",
    "    svm_results[\"recall\"] = recall\n",
    "    svm_results[\"specificity\"] = specificity\n",
    "    svm_results[\"f1\"] = f1\n",
    "\n",
    "  \n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_svm\n",
    "\n",
    "    svm_results = (svm_results, y_plot)\n",
    "    \n",
    "    return svm_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848877b",
   "metadata": {
    "id": "2848877b"
   },
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "881b0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_tree(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    parameters_tree = {}\n",
    "\n",
    " \n",
    "    tree = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    " \n",
    "    grid_search_tree = GridSearchCV(\n",
    "        estimator=tree,\n",
    "        param_grid=parameters_tree,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    tree_cv = grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "  \n",
    "    best_classifier_tree = tree_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_predicted_Mortality_tree = best_classifier_tree.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_tree)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_tree)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_tree)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_tree)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_tree)\n",
    "\n",
    "  \n",
    "    tree_results = {}\n",
    "    tree_results[\"accuracy\"] = accuracy\n",
    "    tree_results[\"precision\"] = precision\n",
    "    tree_results[\"recall\"] = recall\n",
    "    tree_results[\"specificity\"] = specificity\n",
    "    tree_results[\"f1\"] = f1\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_tree\n",
    "\n",
    "    tree_results = (tree_results, y_plot)\n",
    "    \n",
    "    return tree_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a4057",
   "metadata": {
    "id": "d15a4057"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e16b3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    parameters_knn = {}\n",
    "\n",
    " \n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "    grid_search_knn = GridSearchCV(\n",
    "        estimator=knn,\n",
    "        param_grid=parameters_knn,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    knn_cv = grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "    best_classifier_knn = knn_cv.best_estimator_\n",
    "\n",
    "    y_predicted_Mortality_knn = best_classifier_knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_knn)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_knn)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_knn)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_knn)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_knn)\n",
    "\n",
    "    knn_results = {}\n",
    "    knn_results[\"accuracy\"] = accuracy\n",
    "    knn_results[\"precision\"] = precision\n",
    "    knn_results[\"recall\"] = recall\n",
    "    knn_results[\"specificity\"] = specificity\n",
    "    knn_results[\"f1\"] = f1\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_knn\n",
    "\n",
    "    knn_results = (knn_results, y_plot)\n",
    "    \n",
    "    return knn_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db56b9",
   "metadata": {
    "id": "a2db56b9"
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5139caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_forest(X_train, y_train, X_test, y_test):\n",
    "    parameters_forest = {}\n",
    "\n",
    "\n",
    "    forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "    grid_search_forest = GridSearchCV(\n",
    "        estimator=forest,\n",
    "        param_grid=parameters_forest,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    forest_cv = grid_search_forest.fit(X_train, y_train)\n",
    "\n",
    "    best_classifier_forest = forest_cv.best_estimator_\n",
    "\n",
    "    y_predicted_Mortality_forest = best_classifier_forest.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_forest)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_forest)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_forest)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_forest)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_forest)\n",
    "\n",
    "\n",
    "    forest_results = {}\n",
    "    forest_results[\"accuracy\"] = accuracy\n",
    "    forest_results[\"precision\"] = precision\n",
    "    forest_results[\"recall\"] = recall\n",
    "    forest_results[\"specificity\"] = specificity\n",
    "    forest_results[\"f1\"] = f1\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_forest\n",
    "\n",
    "    return forest_results, y_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cce87",
   "metadata": {
    "id": "873cce87"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5879d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_neural(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    parameters_neural = {}\n",
    "\n",
    "\n",
    "    neural = MLPClassifier()\n",
    "\n",
    "    grid_search_neural = GridSearchCV(\n",
    "        estimator=neural,\n",
    "        param_grid=parameters_neural,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    neural_cv = grid_search_neural.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    best_classifier_neural = neural_cv.best_estimator_\n",
    "\n",
    "    \n",
    "    y_predicted_Mortality_neural = best_classifier_neural.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_neural)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_neural)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_neural)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_neural)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_neural)\n",
    "\n",
    " \n",
    "    neural_results = {}\n",
    "    neural_results[\"accuracy\"] = accuracy\n",
    "    neural_results[\"precision\"] = precision\n",
    "    neural_results[\"recall\"] = recall\n",
    "    neural_results[\"specificity\"] = specificity\n",
    "    neural_results[\"f1\"] = f1\n",
    "\n",
    "    \n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_neural\n",
    "\n",
    "    return neural_results, y_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jUZXKSEf50lK",
   "metadata": {
    "id": "jUZXKSEf50lK"
   },
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2715bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_boost(X_train, y_train, X_test, y_test):\n",
    "  \n",
    "    parameters_boost = {}\n",
    "\n",
    " \n",
    "    boost = XGBClassifier()\n",
    "\n",
    "\n",
    "    grid_search_boost = GridSearchCV(\n",
    "        estimator=boost,\n",
    "        param_grid=parameters_boost,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    boost_cv = grid_search_boost.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    best_classifier_boost = boost_cv.best_estimator_\n",
    "\n",
    "\n",
    "    y_predicted_Mortality_boost = best_classifier_boost.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_boost)\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    boost_results = {}\n",
    "    boost_results[\"accuracy\"] = accuracy\n",
    "    boost_results[\"precision\"] = precision\n",
    "    boost_results[\"recall\"] = recall\n",
    "    boost_results[\"specificity\"] = specificity\n",
    "    boost_results[\"f1\"] = f1\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_train \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    return boost_results, y_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f251fc7",
   "metadata": {},
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b3f7bfa",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_Outcome_InhospitalMortality=[]\n",
    "\n",
    "y_train = df_before_normalize['Outcome_InhospitalMortality']\n",
    "y_test = df_test_before_normalize['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22669841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = df_normalize\n",
    "X_test = df_test_normalize.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "\n",
    "y_train_ = pd.DataFrame(y_train)\n",
    "y_test_ = pd.DataFrame(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6118, 76)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1530, 76)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6118, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome_InhospitalMortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1530 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Outcome_InhospitalMortality\n",
       "0                             1.0\n",
       "1                             1.0\n",
       "2                             1.0\n",
       "3                             1.0\n",
       "4                             1.0\n",
       "...                           ...\n",
       "1525                          1.0\n",
       "1526                          0.0\n",
       "1527                          1.0\n",
       "1528                          1.0\n",
       "1529                          1.0\n",
       "\n",
       "[1530 rows x 1 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data selection Mortality Undersampling and and Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso \n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lasso(X_train ,y_train,X_test):\n",
    "    # Perform feature selection using LASSO on the training set\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the absolute coefficients and sort them\n",
    "    absolute_coeffs = np.abs(lasso.coef_)\n",
    "    sorted_indices = np.argsort(absolute_coeffs)[::-1]\n",
    "    \n",
    "    \n",
    "    X_train =pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    # Select the top 2 features with the highest coefficients\n",
    "    selected_features = X_train.columns[sorted_indices[:40]]\n",
    "\n",
    "    # Apply feature selection to both the training and test sets\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected= X_test[selected_features]\n",
    "    \n",
    "    return (pd.DataFrame(X_train_selected), pd.DataFrame(X_test_selected))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mohammad reza\\Desktop\\LLM paper experimrnt\\dataset\\super cleaned and converted to text\\Mortality\\experiment_1_7 ML methods.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y142sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lasso(pd\u001b[39m.\u001b[39;49mDataFrame(X_train) ,pd\u001b[39m.\u001b[39;49mDataFrame(y_train),pd\u001b[39m.\u001b[39;49mDataFrame(X_test))\n",
      "\u001b[1;32mc:\\Users\\Mohammad reza\\Desktop\\LLM paper experimrnt\\dataset\\super cleaned and converted to text\\Mortality\\experiment_1_7 ML methods.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y142sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m X_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y142sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Select the top 2 features with the highest coefficients\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y142sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m selected_features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39;49mcolumns[sorted_indices[:\u001b[39m40\u001b[39;49m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y142sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Apply feature selection to both the training and test sets\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y142sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m X_train_selected \u001b[39m=\u001b[39m X_train[selected_features]\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:994\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(key):\n\u001b[0;32m    988\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    989\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39monly integers, slices (`:`), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mellipsis (`...`), numpy.newaxis (`None`) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand integer or boolean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marrays are valid indices\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n\u001b[1;32m--> 994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5385\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5383\u001b[0m \u001b[39m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5384\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 5385\u001b[0m     disallow_ndim_indexing(result)\n\u001b[0;32m   5387\u001b[0m \u001b[39m# NB: Using _constructor._simple_new would break if MultiIndex\u001b[39;00m\n\u001b[0;32m   5388\u001b[0m \u001b[39m#  didn't override __getitem__\u001b[39;00m\n\u001b[0;32m   5389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor\u001b[39m.\u001b[39m_simple_new(result, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name)\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:341\u001b[0m, in \u001b[0;36mdisallow_ndim_indexing\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mHelper function to disallow multi-dimensional indexing on 1D Series/Index.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39min GH#30588.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(result) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    342\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMulti-dimensional indexing (e.g. `obj[:, None]`) is no longer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported. Convert to a numpy array before indexing instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    }
   ],
   "source": [
    "\n",
    "lasso(pd.DataFrame(X_train) ,pd.DataFrame(y_train),pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def rfe(X_train, y_train, X_test):\n",
    "    # Create a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # Perform RFE to select top 'n_features' features\n",
    "    rfe = RFE(estimator=model, n_features_to_select=40)\n",
    "    X_train_selected = rfe.fit_transform(X_train, y_train)\n",
    "    X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "    return (pd.DataFrame(X_train_selected), pd.DataFrame(X_test_selected))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest_feature_importance(X_train, y_train, X_test):\n",
    "    # Create a random forest classifier\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    # Fit the model to obtain feature importances\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances and sort them in descending order\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    X_train  = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    # Select top 'n_features' features based on importance\n",
    "    selected_features = X_train.columns[indices][:40]\n",
    "\n",
    "    # Apply feature selection to both the training and test sets\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "\n",
    "    return (pd.DataFrame(X_train_selected), pd.DataFrame(X_test_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fun_feature = [lasso, rfe, random_forest_feature_importance]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handeling imbalence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTETomek \n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "def SMOTETomek_mix(X_train,y_train , X_test , y_test):\n",
    "    \n",
    "    tl = SMOTETomek(random_state=42)\n",
    "    X_resampled_train , y_resampled_train = tl.fit_resample(X_train,y_train)\n",
    "    X_resampled_test , y_resampled_test = tl.fit_resample(X_test,y_test)\n",
    "    \n",
    "    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def random_undersampling(X_train,y_train , X_test , y_test):\n",
    "    # Create a random undersampler\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    # Perform random undersampling\n",
    "    X_resampled_train , y_resampled_train = rus.fit_resample(X_train,y_train)\n",
    "    X_resampled_test , y_resampled_test = rus.fit_resample(X_test,y_test)\n",
    "    \n",
    "    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomOverSampler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def random_oversampling(X_train,y_train , X_test , y_test):\n",
    "    # Create a random oversampler\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "    # Perform random oversampling\n",
    "    X_resampled_train , y_resampled_train = ros.fit_resample(X_train,y_train)\n",
    "    X_resampled_test , y_resampled_test = ros.fit_resample(X_test,y_test)\n",
    "    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fun_imbalance = [SMOTETomek_mix, RandomUnderSampler, random_oversampling]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b42d696",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mohammad reza\\Desktop\\LLM paper experimrnt\\dataset\\super cleaned and converted to text\\Mortality\\experiment_1_7 ML methods.ipynb Cell 70\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_train_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m y_test_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m X_train, X_test \u001b[39m=\u001b[39m  fun_feature(X_train, y_train, X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m X_train,y_train_ , X_test , y_test_ \u001b[39m=\u001b[39m fun_imbalanced(X_train,y_train_ , X_test , y_test_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m imbalance_list\u001b[39m.\u001b[39mappend((X_train,y_train_ , X_test , y_test_))\n",
      "\u001b[1;32mc:\\Users\\Mohammad reza\\Desktop\\LLM paper experimrnt\\dataset\\super cleaned and converted to text\\Mortality\\experiment_1_7 ML methods.ipynb Cell 70\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m X_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Select the top 2 features with the highest coefficients\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m selected_features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39;49mcolumns[sorted_indices[:\u001b[39m40\u001b[39;49m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Apply feature selection to both the training and test sets\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mohammad%20reza/Desktop/LLM%20paper%20experimrnt/dataset/super%20cleaned%20and%20converted%20to%20text/Mortality/experiment_1_7%20ML%20methods.ipynb#Y126sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m X_train_selected \u001b[39m=\u001b[39m X_train[selected_features]\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:994\u001b[0m, in \u001b[0;36mRangeIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(key):\n\u001b[0;32m    988\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    989\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39monly integers, slices (`:`), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    990\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mellipsis (`...`), numpy.newaxis (`None`) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand integer or boolean \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marrays are valid indices\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n\u001b[1;32m--> 994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5385\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5383\u001b[0m \u001b[39m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5384\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 5385\u001b[0m     disallow_ndim_indexing(result)\n\u001b[0;32m   5387\u001b[0m \u001b[39m# NB: Using _constructor._simple_new would break if MultiIndex\u001b[39;00m\n\u001b[0;32m   5388\u001b[0m \u001b[39m#  didn't override __getitem__\u001b[39;00m\n\u001b[0;32m   5389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor\u001b[39m.\u001b[39m_simple_new(result, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name)\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:341\u001b[0m, in \u001b[0;36mdisallow_ndim_indexing\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mHelper function to disallow multi-dimensional indexing on 1D Series/Index.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39min GH#30588.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(result) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    342\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMulti-dimensional indexing (e.g. `obj[:, None]`) is no longer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported. Convert to a numpy array before indexing instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    }
   ],
   "source": [
    "list_fun_feature = [lasso, rfe, random_forest_feature_importance]\n",
    "list_fun_imbalance = [SMOTETomek_mix, RandomUnderSampler, random_oversampling]\n",
    "\n",
    "feature_dict_keys = ['SMOTETomek_mix', 'RandomUnderSampler', 'random_oversampling']\n",
    "\n",
    "l = 0\n",
    "feature_dict={}\n",
    "for fun_feature in list_fun_feature:\n",
    "    \n",
    "    X_train = df_normalize\n",
    "    y_train = df_before_normalize[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "    X_test = df_test_normalize.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "    y_test = df_test_before_normalize[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "    y_train_ = pd.DataFrame(y_train['Outcome_InhospitalMortality'])\n",
    "    y_test_ = pd.DataFrame(y_test['Outcome_InhospitalMortality'])\n",
    "    \n",
    "    imbalance_list=[]\n",
    "    for fun_imbalanced  in list_fun_imbalance:\n",
    "        \n",
    "        X_train=np.array(X_train)\n",
    "        X_test=np.array(X_test)\n",
    "\n",
    "        y_train_ = np.array(y_train)\n",
    "        y_test_ = np.array(y_test)\n",
    "        \n",
    "        X_train, X_test =  fun_feature(X_train, y_train, X_test)\n",
    "        X_train,y_train_ , X_test , y_test_ = fun_imbalanced(X_train,y_train_ , X_test , y_test_)\n",
    "        \n",
    "        imbalance_list.append((X_train,y_train_ , X_test , y_test_))\n",
    "        \n",
    "    print(imbalance_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n m\n",
      "m\n",
      "0 1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "lis = [\"n\" ,\"m\"]\n",
    "\n",
    "for a,b in lis,range(len(lis)):\n",
    "    print(a,b)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaec50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Outcome_InhospitalMortality=[]\n",
    "X_train, X_test = lasso_MO_ICU(pd.DataFrame(X_train), y_train_ ,pd.DataFrame(X_test))\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "y_train_ = np.array(y_train['Outcome_InhospitalMortality'])\n",
    "y_test_ = np.array(y_test['Outcome_InhospitalMortality'])\n",
    "\n",
    "X_train,y_train_ , X_test , y_test_ = balancing_dataset(X_train,y_train_ , X_test , y_test_)\n",
    "    \n",
    "list_Outcome_InhospitalMortality.extend([logistic_regression_classifier(X_train, y_train_, X_test, y_test_),\n",
    "                                            train_and_evaluate_svm(X_train, y_train_, X_test, y_test_),\n",
    "                                        train_and_evaluate_tree(X_train, y_train_, X_test, y_test_),\n",
    "                                        train_and_evaluate_knn(X_train, y_train_, X_test, y_test_),\n",
    "                                        train_and_evaluate_forest(X_train, y_train_, X_test, y_test_),\n",
    "                                        train_and_evaluate_neural(X_train, y_train_, X_test, y_test_),\n",
    "                                        train_and_evaluate_boost(X_train, y_train_, X_test, y_test_)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0570e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic_list_Outcome_InhospitalMortality = dict(zip(['logistic_regression', 'svm', 'tree', 'knn', 'forest', 'neural', 'boost'], list_Outcome_InhospitalMortality))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_dict = {}\n",
    "\n",
    "# List of dictionary names and their corresponding dictionaries\n",
    "dict_list = [('Outcome_InhospitalMortality', result_dic_list_Outcome_InhospitalMortality)]\n",
    "\n",
    "# Merge the dictionaries\n",
    "for name, result_dict in dict_list:\n",
    "    merged_dict[name] = result_dict\n",
    "\n",
    "# The merged_dict now contains all the dictionaries merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed56e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(merged_dict)\n",
    "\n",
    "\n",
    "df = df.transpose()\n",
    "\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Method'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for outcome, models in merged_dict.items():\n",
    "    for model, metrics in models.items():\n",
    "        accuracy, precision, recall, specificity, f1 = metrics[0]['accuracy'], metrics[0]['precision'], metrics[0]['recall'], metrics[0]['specificity'], metrics[0]['f1']\n",
    "        y_true, y_predicted = metrics[1]['y_true'], metrics[1]['y_predicted']\n",
    "        data.append([outcome, model, accuracy, precision, recall, specificity, f1, y_true.tolist(), y_predicted.tolist()])\n",
    "\n",
    "columns = ['Outcome', 'Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1', 'y_true', 'y_predicted']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30422537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.341px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
