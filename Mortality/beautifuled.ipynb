{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Lasso\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(df):\n",
    "    # Drop duplicate rows across all columns\n",
    "    df = df.drop_duplicates()\n",
    "    # Drop column: 'L1_BloodGroup_First'\n",
    "    df = df.drop(columns=['L1_BloodGroup_First'])\n",
    "    # Drop columns: 'Symptom_Hemiparesia', 'MH_PregnanAcy' and 22 other columns\n",
    "    return df\n",
    "\n",
    "df_clean = clean_data(df.copy())\n",
    "df= df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ooutcome columns: 1.are Outcome_InhospitalMortality \n",
    "df = df.dropna(subset=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inja oomadim va external validation ro freeze kardim\n",
    "df_internal_validation = df[df['Patient_Hospital']!=\"Hospital2\"]\n",
    "df_external_validation = df[df['Patient_Hospital']==\"Hospital2\"]\n",
    "df_internal_validation = df_internal_validation.drop(columns=['Patient_Hospital'])\n",
    "df_external_validation = df_external_validation.drop(columns=['Patient_Hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_internal_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y  = df_internal_validation[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:800: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_imputed = imputer.fit_transform(X)\n",
    "\n",
    "y_ex = pd.DataFrame(y.loc[ : ,'Outcome_InhospitalMortality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[['Outcome_InhospitalMortality']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex = df_external_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_ex  = df_external_validation[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_imputed_ex = imputer.fit_transform(X_ex)\n",
    "\n",
    "y_ex = pd.DataFrame(y_ex.loc[ : ,'Outcome_InhospitalMortality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(df_imputed,y, test_size = 0.3 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['Outcome_InhospitalMortality']\n",
    "y_test= y_test['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ex =df_imputed_ex #.to_numpy()\n",
    "\n",
    "\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_ex_normalize = transform.fit_transform(arr_ex)\n",
    "df_ex_normalize =pd.DataFrame(df_ex_normalize)\n",
    "df_ex_normalize.columns = X_ex.columns.tolist()\n",
    "\n",
    "X_ex = df_ex_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tain =X_train#.to_numpy()\n",
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_normalize = transform.fit_transform(arr_tain)\n",
    "df_normalize =pd.DataFrame(df_normalize)\n",
    "df_normalize.columns = X.columns.tolist()\n",
    "X_train = df_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "arr =X_test#.to_numpy()\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_test_normalize = transform.fit_transform(arr)\n",
    "df_test_normalize =pd.DataFrame(df_test_normalize)\n",
    "df_test_normalize.columns = X.columns.tolist()\n",
    "X_test =df_test_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.460e-01, tolerance: 8.412e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def lasso_MO_ICU(X_train, y_train,X_test , X_ex):\n",
    "    # Perform feature selection using LASSO on the training set\n",
    "    \n",
    "    lasso = Lasso(alpha=0.0001)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the absolute coefficients and sort them\n",
    "    #absolute_coeffs = np.abs(lasso.coef_)\n",
    "    #sorted_indices = np.argsort(absolute_coeffs)[::-1]\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_ex = pd.DataFrame(X_ex)\n",
    "    # Select the top 2 features with the highest coefficients\n",
    "    #selected_feature_indices = sorted_indices[:40]\n",
    "    selected_feature_indices = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "    # Apply feature selection to both the training and test sets\n",
    "    X_train_selected_Mortality_ICU = X_train.iloc[:, selected_feature_indices]\n",
    "    X_test_selected_Mortality_ICU = X_test.iloc[:, selected_feature_indices]\n",
    "    X_ex = X_ex.iloc[:, selected_feature_indices]\n",
    "    return X_train_selected_Mortality_ICU ,X_test_selected_Mortality_ICU,X_ex\n",
    "\n",
    "X_train,X_test,X_ex = lasso_MO_ICU(X_train, y_train,X_test,X_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def balancing_dataset(X_train,y_train):\n",
    "    \n",
    "    tl = RandomUnderSampler()\n",
    "    X_resampled_train , y_resampled_train = tl.fit_resample(X_train,y_train)\n",
    "    X_resampled_test , y_resampled_test = tl.fit_resample(X_test,y_test)\n",
    "    \n",
    "    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test)\n",
    "a,b, X_test , y_test = balancing_dataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "def logistic_regression_classifier(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {}\n",
    "\n",
    "\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_predicted_Mortality_lr = best_classifier_lr.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_lr)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_lr)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_lr)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_lr)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_lr)\n",
    "\n",
    "\n",
    "    Logistic_Regression = {}\n",
    "    Logistic_Regression[\"accuracy\"] = accuracy\n",
    "    Logistic_Regression[\"precision\"] = precision\n",
    "    Logistic_Regression[\"recall\"] = recall\n",
    "    Logistic_Regression[\"specificity\"] = specificity\n",
    "    Logistic_Regression[\"f1\"] = f1\n",
    "    Logistic_Regression[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_lr)\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_lr\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_lr.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    Logistic_Regression[\"accuracy_ex\"] = accuracy\n",
    "    Logistic_Regression[\"precision_ex\"] = precision\n",
    "    Logistic_Regression[\"recall_ex\"] = recall\n",
    "    Logistic_Regression[\"specificity_ex\"] = specificity\n",
    "    Logistic_Regression[\"f1_ex\"] = f1\n",
    "    Logistic_Regression[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_svm(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    svm_classifier = svm.SVC(random_state=42)\n",
    "\n",
    "\n",
    "    parameters_svm = {}\n",
    "\n",
    "\n",
    "    grid_search_svm = GridSearchCV(\n",
    "        estimator=svm_classifier,\n",
    "        param_grid=parameters_svm,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "   \n",
    "    svm_cv = grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    " \n",
    "    best_classifier_svm = svm_cv.best_estimator_\n",
    "\n",
    "\n",
    "    y_predicted_Mortality_svm = best_classifier_svm.predict(X_test)\n",
    "\n",
    "   \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_svm)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_svm)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_svm)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_svm)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_svm)\n",
    "\n",
    "    svm_results = {}\n",
    "    svm_results[\"accuracy\"] = accuracy\n",
    "    svm_results[\"precision\"] = precision\n",
    "    svm_results[\"recall\"] = recall\n",
    "    svm_results[\"specificity\"] = specificity\n",
    "    svm_results[\"f1\"] = f1\n",
    "    svm_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_svm)\n",
    "\n",
    "  \n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_svm\n",
    "\n",
    "    y_predicted_Mortality_boost = best_classifier_svm.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    svm_results[\"accuracy_ex\"] = accuracy\n",
    "    svm_results[\"precision_ex\"] = precision\n",
    "    svm_results[\"recall_ex\"] = recall\n",
    "    svm_results[\"specificity_ex\"] = specificity\n",
    "    svm_results[\"f1_ex\"] = f1\n",
    "    svm_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] =y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    svm_results = (svm_results, y_plot)\n",
    "    \n",
    "    return svm_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_tree(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_tree = {}\n",
    "\n",
    " \n",
    "    tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    " \n",
    "    grid_search_tree = GridSearchCV(\n",
    "        estimator=tree,\n",
    "        param_grid=parameters_tree,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    tree_cv = grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "  \n",
    "    best_classifier_tree = tree_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_predicted_Mortality_tree = best_classifier_tree.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_tree)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_tree)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_tree)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_tree)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_tree)\n",
    "\n",
    "  \n",
    "    tree_results = {}\n",
    "    tree_results[\"accuracy\"] = accuracy\n",
    "    tree_results[\"precision\"] = precision\n",
    "    tree_results[\"recall\"] = recall\n",
    "    tree_results[\"specificity\"] = specificity\n",
    "    tree_results[\"f1\"] = f1\n",
    "    tree_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_tree)\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_tree\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_tree.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    tree_results[\"accuracy_ex\"] = accuracy\n",
    "    tree_results[\"precision_ex\"] = precision\n",
    "    tree_results[\"recall_ex\"] = recall\n",
    "    tree_results[\"specificity_ex\"] = specificity\n",
    "    tree_results[\"f1_ex\"] = f1\n",
    "    tree_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    tree_results = (tree_results, y_plot)\n",
    "    \n",
    "    return tree_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_knn = {}\n",
    "\n",
    " \n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "    grid_search_knn = GridSearchCV(\n",
    "        estimator=knn,\n",
    "        param_grid=parameters_knn,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    knn_cv = grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "    best_classifier_knn = knn_cv.best_estimator_\n",
    "\n",
    "    y_predicted_Mortality_knn = best_classifier_knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_knn)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_knn)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_knn)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_knn)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_knn)\n",
    "\n",
    "    knn_results = {}\n",
    "    knn_results[\"accuracy\"] = accuracy\n",
    "    knn_results[\"precision\"] = precision\n",
    "    knn_results[\"recall\"] = recall\n",
    "    knn_results[\"specificity\"] = specificity\n",
    "    knn_results[\"f1\"] = f1\n",
    "    knn_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_knn)\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_knn\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_knn.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    knn_results[\"accuracy_ex\"] = accuracy\n",
    "    knn_results[\"precision_ex\"] = precision\n",
    "    knn_results[\"recall_ex\"] = recall\n",
    "    knn_results[\"specificity_ex\"] = specificity\n",
    "    knn_results[\"f1_ex\"] = f1\n",
    "    knn_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    knn_results = (knn_results, y_plot)\n",
    "    \n",
    "    return knn_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_forest(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "    parameters_forest = {}\n",
    "\n",
    "\n",
    "    forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "    grid_search_forest = GridSearchCV(\n",
    "        estimator=forest,\n",
    "        param_grid=parameters_forest,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    forest_cv = grid_search_forest.fit(X_train, y_train)\n",
    "\n",
    "    best_classifier_forest = forest_cv.best_estimator_\n",
    "\n",
    "    y_predicted_Mortality_forest = best_classifier_forest.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_forest)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_forest)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_forest)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_forest)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_forest)\n",
    "\n",
    "\n",
    "    forest_results = {}\n",
    "    forest_results[\"accuracy\"] = accuracy\n",
    "    forest_results[\"precision\"] = precision\n",
    "    forest_results[\"recall\"] = recall\n",
    "    forest_results[\"specificity\"] = specificity\n",
    "    forest_results[\"f1\"] = f1\n",
    "    forest_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_forest)\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_forest\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_forest.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    forest_results[\"accuracy_ex\"] = accuracy\n",
    "    forest_results[\"precision_ex\"] = precision\n",
    "    forest_results[\"recall_ex\"] = recall\n",
    "    forest_results[\"specificity_ex\"] = specificity\n",
    "    forest_results[\"f1_ex\"] = f1\n",
    "    forest_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    return forest_results, y_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_neural(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_neural = {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50)],  # You can adjust the architecture here\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001],\n",
    "        'max_iter': [200],\n",
    "        'random_state': [42],\n",
    "        'early_stopping': [True],\n",
    "        'validation_fraction': [0.1],\n",
    "        'n_iter_no_change': [10]\n",
    "    }\n",
    "\n",
    "\n",
    "    neural = MLPClassifier()\n",
    "\n",
    "    grid_search_neural = GridSearchCV(\n",
    "        estimator=neural,\n",
    "        param_grid=parameters_neural,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    neural_cv = grid_search_neural.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    best_classifier_neural = neural_cv.best_estimator_\n",
    "\n",
    "    \n",
    "    y_predicted_Mortality_neural = best_classifier_neural.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_neural)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_neural)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_neural)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_neural)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_neural)\n",
    "\n",
    " \n",
    "    neural_results = {}\n",
    "    neural_results[\"accuracy\"] = accuracy\n",
    "    neural_results[\"precision\"] = precision\n",
    "    neural_results[\"recall\"] = recall\n",
    "    neural_results[\"specificity\"] = specificity\n",
    "    neural_results[\"f1\"] = f1\n",
    "    neural_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_neural)\n",
    "\n",
    "    \n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_neural\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_neural.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    neural_results[\"accuracy_ex\"] = accuracy\n",
    "    neural_results[\"precision_ex\"] = precision\n",
    "    neural_results[\"recall_ex\"] = recall\n",
    "    neural_results[\"specificity_ex\"] = specificity\n",
    "    neural_results[\"f1_ex\"] = f1\n",
    "    neural_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] =y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    return neural_results, y_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_boost(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "  \n",
    "    parameters_boost = {}\n",
    "\n",
    " \n",
    "    boost = XGBClassifier()\n",
    "\n",
    "\n",
    "    grid_search_boost = GridSearchCV(\n",
    "        estimator=boost,\n",
    "        param_grid=parameters_boost,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    boost_cv = grid_search_boost.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    best_classifier_boost = boost_cv.best_estimator_\n",
    "\n",
    "\n",
    "    y_predicted_Mortality_boost = best_classifier_boost.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    boost_results = {}\n",
    "    boost_results[\"accuracy\"] = accuracy\n",
    "    boost_results[\"precision\"] = precision\n",
    "    boost_results[\"recall\"] = recall\n",
    "    boost_results[\"specificity\"] = specificity\n",
    "    boost_results[\"f1\"] = f1\n",
    "    boost_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_boost)\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_boost.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    boost_results[\"accuracy_ex\"] = accuracy\n",
    "    boost_results[\"precision_ex\"] = precision\n",
    "    boost_results[\"recall_ex\"] = recall\n",
    "    boost_results[\"specificity_ex\"] = specificity\n",
    "    boost_results[\"f1_ex\"] = f1\n",
    "    boost_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    return boost_results, y_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Outcome_InhospitalMortality=[]\n",
    "y_train_ = pd.DataFrame(y_train)\n",
    "y_test_ = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.array(y_train)\n",
    "y_test_ = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(X_test)\n",
    "y_ex_ = np.array(y_ex['Outcome_InhospitalMortality'].tolist())\n",
    "X_ex = np.array(X_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_Outcome_InhospitalMortality.extend([logistic_regression_classifier(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_svm(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_tree(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_knn(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_forest(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_neural(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_boost(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_)])\n",
    "\n",
    "\n",
    "result_dic_list_Outcome_InhospitalMortality = dict(zip(['logistic_regression', 'svm', 'tree', 'knn', 'forest', 'neural', 'boost'], list_Outcome_InhospitalMortality))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged_dict = {}\n",
    "\n",
    "# List of dictionary names and their corresponding dictionaries\n",
    "dict_list = [('Outcome_InhospitalMortality', result_dic_list_Outcome_InhospitalMortality)]\n",
    "\n",
    "# Merge the dictionaries\n",
    "for name, result_dict in dict_list:\n",
    "    merged_dict[name] = result_dict\n",
    "\n",
    "# The merged_dict now contains all the dictionaries merged together\n",
    "\n",
    "\n",
    "df = pd.DataFrame(merged_dict)\n",
    "\n",
    "\n",
    "df = df.transpose()\n",
    "\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Method'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for outcome, models in merged_dict.items():\n",
    "    for model, metrics in models.items():\n",
    "        accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex = metrics[0]['accuracy'], metrics[0]['precision'], metrics[0]['recall'], metrics[0]['specificity'], metrics[0]['f1'], metrics[0]['AUC'],metrics[0]['accuracy_ex'], metrics[0]['precision_ex'], metrics[0]['recall_ex'], metrics[0]['specificity_ex'], metrics[0]['f1_ex'], metrics[0]['AUC_ex']\n",
    "        y_true, y_predicted,y_true_ex,y_predicted_ex = metrics[1]['y_true'], metrics[1]['y_predicted'],metrics[1]['y_true_ex'], metrics[1]['y_predicted_ex']\n",
    "        data.append([outcome, model,accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex, y_true.tolist(), y_predicted.tolist(),y_true_ex.tolist(),y_predicted_ex.tolist()])\n",
    "\n",
    "columns = ['Outcome', 'Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1','AUC', 'Accuracy_ex', 'Precision_ex', 'Recall_ex', 'Specificity_ex', 'F1_ex','AUC_ex', 'y_true', 'y_predicted', 'y_true_ex', 'y_predicted_ex']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_ex</th>\n",
       "      <th>Precision_ex</th>\n",
       "      <th>Recall_ex</th>\n",
       "      <th>Specificity_ex</th>\n",
       "      <th>F1_ex</th>\n",
       "      <th>AUC_ex</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_predicted</th>\n",
       "      <th>y_true_ex</th>\n",
       "      <th>y_predicted_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.659375</td>\n",
       "      <td>0.614009</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.460417</td>\n",
       "      <td>0.715899</td>\n",
       "      <td>0.659375</td>\n",
       "      <td>0.766335</td>\n",
       "      <td>0.843561</td>\n",
       "      <td>0.868327</td>\n",
       "      <td>0.362676</td>\n",
       "      <td>0.855765</td>\n",
       "      <td>0.615502</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.586458</td>\n",
       "      <td>0.547866</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.705271</td>\n",
       "      <td>0.586458</td>\n",
       "      <td>0.808949</td>\n",
       "      <td>0.819746</td>\n",
       "      <td>0.975089</td>\n",
       "      <td>0.151408</td>\n",
       "      <td>0.890695</td>\n",
       "      <td>0.563249</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>tree</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.570946</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.630597</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.678267</td>\n",
       "      <td>0.822286</td>\n",
       "      <td>0.761566</td>\n",
       "      <td>0.348592</td>\n",
       "      <td>0.790762</td>\n",
       "      <td>0.555079</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.525952</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.143750</td>\n",
       "      <td>0.677060</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.808980</td>\n",
       "      <td>0.945730</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>0.872026</td>\n",
       "      <td>0.530963</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>forest</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.813210</td>\n",
       "      <td>0.844125</td>\n",
       "      <td>0.939502</td>\n",
       "      <td>0.313380</td>\n",
       "      <td>0.889263</td>\n",
       "      <td>0.626441</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.676042</td>\n",
       "      <td>0.614344</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.744873</td>\n",
       "      <td>0.676042</td>\n",
       "      <td>0.814631</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.922598</td>\n",
       "      <td>0.387324</td>\n",
       "      <td>0.888223</td>\n",
       "      <td>0.654961</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>boost</td>\n",
       "      <td>0.642708</td>\n",
       "      <td>0.588846</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.339583</td>\n",
       "      <td>0.725819</td>\n",
       "      <td>0.642708</td>\n",
       "      <td>0.803977</td>\n",
       "      <td>0.851575</td>\n",
       "      <td>0.913701</td>\n",
       "      <td>0.369718</td>\n",
       "      <td>0.881545</td>\n",
       "      <td>0.641710</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Outcome                Model  Accuracy  Precision  \\\n",
       "0  Outcome_InhospitalMortality  logistic_regression  0.659375   0.614009   \n",
       "1  Outcome_InhospitalMortality                  svm  0.586458   0.547866   \n",
       "2  Outcome_InhospitalMortality                 tree  0.587500   0.570946   \n",
       "3  Outcome_InhospitalMortality                  knn  0.546875   0.525952   \n",
       "4  Outcome_InhospitalMortality               forest  0.654167   0.594872   \n",
       "5  Outcome_InhospitalMortality               neural  0.676042   0.614344   \n",
       "6  Outcome_InhospitalMortality                boost  0.642708   0.588846   \n",
       "\n",
       "     Recall  Specificity        F1       AUC  Accuracy_ex  Precision_ex  \\\n",
       "0  0.858333     0.460417  0.715899  0.659375     0.766335      0.843561   \n",
       "1  0.989583     0.183333  0.705271  0.586458     0.808949      0.819746   \n",
       "2  0.704167     0.470833  0.630597  0.587500     0.678267      0.822286   \n",
       "3  0.950000     0.143750  0.677060  0.546875     0.778409      0.808980   \n",
       "4  0.966667     0.341667  0.736508  0.654167     0.813210      0.844125   \n",
       "5  0.945833     0.406250  0.744873  0.676042     0.814631      0.856317   \n",
       "6  0.945833     0.339583  0.725819  0.642708     0.803977      0.851575   \n",
       "\n",
       "   Recall_ex  Specificity_ex     F1_ex    AUC_ex  \\\n",
       "0   0.868327        0.362676  0.855765  0.615502   \n",
       "1   0.975089        0.151408  0.890695  0.563249   \n",
       "2   0.761566        0.348592  0.790762  0.555079   \n",
       "3   0.945730        0.116197  0.872026  0.530963   \n",
       "4   0.939502        0.313380  0.889263  0.626441   \n",
       "5   0.922598        0.387324  0.888223  0.654961   \n",
       "6   0.913701        0.369718  0.881545  0.641710   \n",
       "\n",
       "                                              y_true  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         y_predicted  \\\n",
       "0  [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
       "2  [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
       "5  [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...   \n",
       "6  [1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, ...   \n",
       "\n",
       "                                           y_true_ex  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                      y_predicted_ex  \n",
       "0  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, ...  \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "2  [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, ...  \n",
       "3  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "4  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "5  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "6  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
