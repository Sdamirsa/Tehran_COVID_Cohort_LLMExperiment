{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa37cf1a",
   "metadata": {
    "id": "aa37cf1a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3e4a4",
   "metadata": {},
   "source": [
    "# Train and Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe0678",
   "metadata": {},
   "source": [
    "## Training set (imputing and normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e641ad",
   "metadata": {
    "id": "78e641ad"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31dd444f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "31dd444f",
    "outputId": "4443d0a9-6836-40a9-917b-c88804ba69ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Hospital</th>\n",
       "      <th>Outcome_InhospitalMortality</th>\n",
       "      <th>Outcome_ICUadmission</th>\n",
       "      <th>TM_S_Intubation</th>\n",
       "      <th>TM_S_Dialysis</th>\n",
       "      <th>L1_BloodGroup_First</th>\n",
       "      <th>Demographic_Gender</th>\n",
       "      <th>Symptom_Caugh</th>\n",
       "      <th>Symptom_Dyspnea</th>\n",
       "      <th>Symptom_Fever</th>\n",
       "      <th>...</th>\n",
       "      <th>LAB_CR_1</th>\n",
       "      <th>LAB_NA_First</th>\n",
       "      <th>LAB_K_First</th>\n",
       "      <th>LAB_ALKP_First</th>\n",
       "      <th>LAB_ESR_First</th>\n",
       "      <th>LAB_CPK_First</th>\n",
       "      <th>LAB_PTT_First</th>\n",
       "      <th>LAB_PT_First</th>\n",
       "      <th>LAB_INR_First</th>\n",
       "      <th>Demographic_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospital1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hospital1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospital1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hospital1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>139.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.31</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospital1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>139.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.31</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_Hospital  Outcome_InhospitalMortality  Outcome_ICUadmission  \\\n",
       "0        Hospital1                          0.0                     1   \n",
       "1        Hospital1                          0.0                     1   \n",
       "2        Hospital1                          0.0                     1   \n",
       "3        Hospital1                          1.0                     1   \n",
       "4        Hospital1                          1.0                     1   \n",
       "\n",
       "   TM_S_Intubation  TM_S_Dialysis  L1_BloodGroup_First  Demographic_Gender  \\\n",
       "0                1              1                  0.0                 1.0   \n",
       "1                1              0                  NaN                 1.0   \n",
       "2                0              1                  NaN                 1.0   \n",
       "3                0              0                  NaN                 1.0   \n",
       "4                0              0                  NaN                 1.0   \n",
       "\n",
       "   Symptom_Caugh  Symptom_Dyspnea  Symptom_Fever  ...  LAB_CR_1  LAB_NA_First  \\\n",
       "0              1                1              0  ...       NaN         140.0   \n",
       "1              1                1              0  ...       1.1         139.0   \n",
       "2              0                1              0  ...       0.9         138.0   \n",
       "3              0                1              1  ...       1.2         137.0   \n",
       "4              0                1              1  ...       1.2         137.0   \n",
       "\n",
       "   LAB_K_First  LAB_ALKP_First  LAB_ESR_First  LAB_CPK_First  LAB_PTT_First  \\\n",
       "0          4.0           181.0           62.0          661.0           32.6   \n",
       "1          3.5            98.0           30.0          179.0           37.6   \n",
       "2          4.2            99.0           29.0         1956.0           27.4   \n",
       "3          4.7           139.0           20.0           30.0           29.1   \n",
       "4          4.7           139.0           20.0           30.0           29.1   \n",
       "\n",
       "   LAB_PT_First  LAB_INR_First  Demographic_Age  \n",
       "0          10.9           1.00             33.0  \n",
       "1          10.8           0.99             44.0  \n",
       "2          12.1           1.11             50.0  \n",
       "3          14.2           1.31             71.0  \n",
       "4          14.2           1.31             71.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa2e9cb",
   "metadata": {
    "id": "5aa2e9cb"
   },
   "outputs": [],
   "source": [
    "# ooutcome columns: 1.are Outcome_InhospitalMortality \n",
    "df = df.dropna(subset=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c278d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.shape[1]\n",
    "min_non_null = int(0.3 * num_cols)\n",
    "df = df.dropna(thresh=min_non_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea49b803",
   "metadata": {
    "id": "ea49b803"
   },
   "outputs": [],
   "source": [
    "#inja oomadim va external validation ro freeze kardim\n",
    "df_internal_validation = df[df['Patient_Hospital']!=\"Hospital2\"]\n",
    "df_external_validation = df[df['Patient_Hospital']==\"Hospital2\"]\n",
    "df_internal_validation = df_internal_validation.drop(columns=['Patient_Hospital'])\n",
    "df_external_validation = df_external_validation.drop(columns=['Patient_Hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d91627",
   "metadata": {
    "id": "31d91627"
   },
   "outputs": [],
   "source": [
    "#inja train test split kardim va target variable ro jodakardim\n",
    "# Define features (X) and target variable (y)\n",
    "X = df_internal_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y  = df_internal_validation[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "# Perform the train-test split (adjust the test_size as needed)\n",
    "#X_train , X_test , y_train , y_test = train_test_split(X,y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_BloodGroup_First</th>\n",
       "      <th>Demographic_Gender</th>\n",
       "      <th>Symptom_Caugh</th>\n",
       "      <th>Symptom_Dyspnea</th>\n",
       "      <th>Symptom_Fever</th>\n",
       "      <th>Symptom_Chiver</th>\n",
       "      <th>Symptom_Mylagia</th>\n",
       "      <th>Symptom_Weakness</th>\n",
       "      <th>Symptom_LOC</th>\n",
       "      <th>Symptom_Sore through</th>\n",
       "      <th>...</th>\n",
       "      <th>LAB_CR_1</th>\n",
       "      <th>LAB_NA_First</th>\n",
       "      <th>LAB_K_First</th>\n",
       "      <th>LAB_ALKP_First</th>\n",
       "      <th>LAB_ESR_First</th>\n",
       "      <th>LAB_CPK_First</th>\n",
       "      <th>LAB_PTT_First</th>\n",
       "      <th>LAB_PT_First</th>\n",
       "      <th>LAB_INR_First</th>\n",
       "      <th>Demographic_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>139.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.31</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>139.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.31</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7648 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      L1_BloodGroup_First  Demographic_Gender  Symptom_Caugh  Symptom_Dyspnea  \\\n",
       "0                     0.0                 1.0              1                1   \n",
       "1                     NaN                 1.0              1                1   \n",
       "2                     NaN                 1.0              0                1   \n",
       "3                     NaN                 1.0              0                1   \n",
       "4                     NaN                 1.0              0                1   \n",
       "...                   ...                 ...            ...              ...   \n",
       "9129                  NaN                 0.0              1                1   \n",
       "9130                  NaN                 1.0              1                1   \n",
       "9131                  NaN                 0.0              1                1   \n",
       "9132                  NaN                 1.0              1                1   \n",
       "9133                  NaN                 1.0              1                1   \n",
       "\n",
       "      Symptom_Fever  Symptom_Chiver  Symptom_Mylagia  Symptom_Weakness  \\\n",
       "0                 0               0                0                 1   \n",
       "1                 0               0                1                 0   \n",
       "2                 0               0                1                 1   \n",
       "3                 1               0                1                 1   \n",
       "4                 1               0                1                 1   \n",
       "...             ...             ...              ...               ...   \n",
       "9129              0               0                1                 1   \n",
       "9130              1               0                1                 1   \n",
       "9131              1               1                1                 1   \n",
       "9132              0               1                1                 1   \n",
       "9133              0               0                1                 0   \n",
       "\n",
       "      Symptom_LOC  Symptom_Sore through  ...  LAB_CR_1  LAB_NA_First  \\\n",
       "0             0.0                     0  ...       NaN         140.0   \n",
       "1             0.0                     0  ...       1.1         139.0   \n",
       "2             0.0                     0  ...       0.9         138.0   \n",
       "3             0.0                     0  ...       1.2         137.0   \n",
       "4             0.0                     0  ...       1.2         137.0   \n",
       "...           ...                   ...  ...       ...           ...   \n",
       "9129          0.0                     0  ...       NaN           NaN   \n",
       "9130          0.0                     0  ...       NaN           NaN   \n",
       "9131          0.0                     0  ...       NaN           NaN   \n",
       "9132          0.0                     0  ...       NaN           NaN   \n",
       "9133          0.0                     0  ...       NaN           NaN   \n",
       "\n",
       "      LAB_K_First  LAB_ALKP_First  LAB_ESR_First  LAB_CPK_First  \\\n",
       "0             4.0           181.0           62.0          661.0   \n",
       "1             3.5            98.0           30.0          179.0   \n",
       "2             4.2            99.0           29.0         1956.0   \n",
       "3             4.7           139.0           20.0           30.0   \n",
       "4             4.7           139.0           20.0           30.0   \n",
       "...           ...             ...            ...            ...   \n",
       "9129          NaN             NaN            NaN            NaN   \n",
       "9130          NaN             NaN            NaN            NaN   \n",
       "9131          NaN             NaN            NaN            NaN   \n",
       "9132          NaN             NaN            NaN            NaN   \n",
       "9133          NaN             NaN            NaN            NaN   \n",
       "\n",
       "      LAB_PTT_First  LAB_PT_First  LAB_INR_First  Demographic_Age  \n",
       "0              32.6          10.9           1.00             33.0  \n",
       "1              37.6          10.8           0.99             44.0  \n",
       "2              27.4          12.1           1.11             50.0  \n",
       "3              29.1          14.2           1.31             71.0  \n",
       "4              29.1          14.2           1.31             71.0  \n",
       "...             ...           ...            ...              ...  \n",
       "9129            NaN           NaN            NaN             88.0  \n",
       "9130            NaN           NaN            NaN             51.0  \n",
       "9131            NaN           NaN            NaN             64.0  \n",
       "9132            NaN           NaN            NaN             38.0  \n",
       "9133            NaN           NaN            NaN             91.0  \n",
       "\n",
       "[7648 rows x 76 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c05e69",
   "metadata": {
    "id": "57c05e69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:800: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\n",
    "'''cat_col=[]\n",
    "num_col=[]\n",
    "for i in range(len(X.columns)):\n",
    "    if i <=52:\n",
    "        cat_col.append(X.columns[i])\n",
    "    else:\n",
    "        num_col.append(X.columns[i])\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "X_train_array  =X.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed = imputer.fit_transform(X_train_array)\n",
    "df_imputed = pd.DataFrame(imputed)\n",
    "df_imputed.columns=pd.DataFrame(X).columns.tolist()\n",
    "\n",
    "for i in cat_col:\n",
    "    df_imputed[[i]] = df_imputed[[i]].round()\n",
    "df_imputed.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)'''\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_imputed = imputer.fit_transform(X)\n",
    "\n",
    "y_ex = pd.DataFrame(y.loc[ : ,'Outcome_InhospitalMortality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  1.        , ..., 10.9       ,\n",
       "         1.        , 33.        ],\n",
       "       [ 6.00822846,  1.        ,  1.        , ..., 10.8       ,\n",
       "         0.99      , 44.        ],\n",
       "       [ 6.70454274,  1.        ,  0.        , ..., 12.1       ,\n",
       "         1.11      , 50.        ],\n",
       "       ...,\n",
       "       [ 6.16555245,  0.        ,  1.        , ..., 26.14226317,\n",
       "         7.92835073, 64.        ],\n",
       "       [ 6.22883396,  1.        ,  1.        , ..., 29.02775869,\n",
       "         8.80314081, 38.        ],\n",
       "       [ 6.22760489,  1.        ,  1.        , ..., 31.00514133,\n",
       "         9.80754879, 91.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13dbcf8",
   "metadata": {
    "id": "e13dbcf8"
   },
   "source": [
    "## Test set (imputing and normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf48fe2a",
   "metadata": {
    "id": "cf48fe2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\\ncat_col=[]\\nnum_col=[]\\nfor i in range(len(X_test.columns)):\\n    if i <=52:\\n        cat_col.append(X_test.columns[i])\\n    else:\\n        num_col.append(X_test.columns[i])\\n\\nfrom sklearn.impute import KNNImputer\\nX_test_array  =X_test.to_numpy()\\nimputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\\nimputed_test = imputer.fit_transform(X_test_array)\\ndf_imputed_test = pd.DataFrame(imputed_test)\\ndf_imputed_test.columns=pd.DataFrame(X_test).columns.tolist()\\n\\nfor i in cat_col:\\n    df_imputed_test[[i]] = df_imputed_test[[i]].round()\\ndf_imputed_test.reset_index(drop=True, inplace=True)\\ny_test.reset_index(drop=True, inplace=True)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\n",
    "cat_col=[]\n",
    "num_col=[]\n",
    "for i in range(len(X_test.columns)):\n",
    "    if i <=52:\n",
    "        cat_col.append(X_test.columns[i])\n",
    "    else:\n",
    "        num_col.append(X_test.columns[i])\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "X_test_array  =X_test.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed_test = imputer.fit_transform(X_test_array)\n",
    "df_imputed_test = pd.DataFrame(imputed_test)\n",
    "df_imputed_test.columns=pd.DataFrame(X_test).columns.tolist()\n",
    "\n",
    "for i in cat_col:\n",
    "    df_imputed_test[[i]] = df_imputed_test[[i]].round()\n",
    "df_imputed_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[['Outcome_InhospitalMortality']]\n",
    "#y_test = y_test[['Outcome_InhospitalMortality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf5932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex = df_external_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_ex  = df_external_validation[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "'''cat_col_ex=[]\n",
    "num_col_ex=[]\n",
    "for i in range(len(X_ex.columns)):\n",
    "    if i <=52:\n",
    "        cat_col_ex.append(X_ex.columns[i])\n",
    "    else:\n",
    "        num_col_ex.append(X_ex.columns[i])\n",
    "from sklearn.impute import KNNImputer\n",
    "X_ex_array  =X_ex.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed_ex = imputer.fit_transform(X_ex_array)\n",
    "df_imputed_ex = pd.DataFrame(imputed_ex)\n",
    "df_imputed_ex.columns=pd.DataFrame(X_ex).columns.tolist()\n",
    "\n",
    "for i in cat_col:\n",
    "    df_imputed_ex[[i]] = df_imputed_ex[[i]].round()\n",
    "df_imputed_ex.reset_index(drop=True, inplace=True)\n",
    "y_ex.reset_index(drop=True, inplace=True)\n",
    "'''\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Example using iterative imputation\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_imputed_ex = imputer.fit_transform(X_ex)\n",
    "\n",
    "y_ex = pd.DataFrame(y_ex.loc[ : ,'Outcome_InhospitalMortality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c67897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_BloodGroup_First</th>\n",
       "      <th>Demographic_Gender</th>\n",
       "      <th>Symptom_Caugh</th>\n",
       "      <th>Symptom_Dyspnea</th>\n",
       "      <th>Symptom_Fever</th>\n",
       "      <th>Symptom_Chiver</th>\n",
       "      <th>Symptom_Mylagia</th>\n",
       "      <th>Symptom_Weakness</th>\n",
       "      <th>Symptom_LOC</th>\n",
       "      <th>Symptom_Sore through</th>\n",
       "      <th>...</th>\n",
       "      <th>LAB_CR_1</th>\n",
       "      <th>LAB_NA_First</th>\n",
       "      <th>LAB_K_First</th>\n",
       "      <th>LAB_ALKP_First</th>\n",
       "      <th>LAB_ESR_First</th>\n",
       "      <th>LAB_CPK_First</th>\n",
       "      <th>LAB_PTT_First</th>\n",
       "      <th>LAB_PT_First</th>\n",
       "      <th>LAB_INR_First</th>\n",
       "      <th>Demographic_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>211.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9063</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9065</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9066</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9067</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1409 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      L1_BloodGroup_First  Demographic_Gender  Symptom_Caugh  Symptom_Dyspnea  \\\n",
       "2622                  NaN                 0.0              0                1   \n",
       "2653                  NaN                 1.0              1                1   \n",
       "4404                  NaN                 1.0              0                1   \n",
       "4405                  NaN                 0.0              0                0   \n",
       "4406                  4.0                 1.0              0                0   \n",
       "...                   ...                 ...            ...              ...   \n",
       "9062                  NaN                 0.0              0                0   \n",
       "9063                  NaN                 1.0              0                0   \n",
       "9065                  NaN                 1.0              0                1   \n",
       "9066                  NaN                 0.0              0                0   \n",
       "9067                  NaN                 1.0              0                0   \n",
       "\n",
       "      Symptom_Fever  Symptom_Chiver  Symptom_Mylagia  Symptom_Weakness  \\\n",
       "2622              0               0                0                 0   \n",
       "2653              1               0                0                 0   \n",
       "4404              0               0                0                 0   \n",
       "4405              0               0                0                 1   \n",
       "4406              0               0                0                 1   \n",
       "...             ...             ...              ...               ...   \n",
       "9062              0               0                1                 1   \n",
       "9063              0               0                0                 0   \n",
       "9065              1               1                1                 0   \n",
       "9066              0               0                0                 0   \n",
       "9067              0               0                0                 0   \n",
       "\n",
       "      Symptom_LOC  Symptom_Sore through  ...  LAB_CR_1  LAB_NA_First  \\\n",
       "2622          0.0                     0  ...       NaN           NaN   \n",
       "2653          0.0                     0  ...       NaN           NaN   \n",
       "4404          1.0                     0  ...       NaN           NaN   \n",
       "4405          0.0                     0  ...       0.9         142.0   \n",
       "4406          0.0                     0  ...       1.4         140.0   \n",
       "...           ...                   ...  ...       ...           ...   \n",
       "9062          0.0                     0  ...       NaN           NaN   \n",
       "9063          0.0                     0  ...       NaN           NaN   \n",
       "9065          0.0                     0  ...       NaN           NaN   \n",
       "9066          1.0                     0  ...       NaN           NaN   \n",
       "9067          0.0                     0  ...       NaN           NaN   \n",
       "\n",
       "      LAB_K_First  LAB_ALKP_First  LAB_ESR_First  LAB_CPK_First  \\\n",
       "2622          NaN             NaN            NaN            NaN   \n",
       "2653          NaN             NaN            NaN            NaN   \n",
       "4404          NaN             NaN            NaN            NaN   \n",
       "4405          4.4             NaN            9.0           68.0   \n",
       "4406          4.3           211.0            NaN           49.0   \n",
       "...           ...             ...            ...            ...   \n",
       "9062          NaN             NaN            NaN            NaN   \n",
       "9063          NaN             NaN            NaN            NaN   \n",
       "9065          NaN             NaN            NaN            NaN   \n",
       "9066          NaN             NaN            NaN            NaN   \n",
       "9067          NaN             NaN            NaN            NaN   \n",
       "\n",
       "      LAB_PTT_First  LAB_PT_First  LAB_INR_First  Demographic_Age  \n",
       "2622            NaN           NaN            NaN             61.0  \n",
       "2653            NaN           NaN            NaN             49.0  \n",
       "4404            NaN           NaN            NaN             58.0  \n",
       "4405           35.0          12.0            1.0             14.0  \n",
       "4406           39.0          12.0            1.0             57.0  \n",
       "...             ...           ...            ...              ...  \n",
       "9062            NaN           NaN            NaN             34.0  \n",
       "9063            NaN           NaN            NaN             32.0  \n",
       "9065            NaN           NaN            NaN             74.0  \n",
       "9066            NaN           NaN            NaN             68.0  \n",
       "9067            NaN           NaN            NaN             67.0  \n",
       "\n",
       "[1409 rows x 76 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e90bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(df_imputed,y, test_size = 0.3 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf092af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['Outcome_InhospitalMortality']\n",
    "y_test= y_test['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471336f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ex =df_imputed_ex #.to_numpy()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_ex_normalize = transform.fit_transform(arr_ex)\n",
    "df_ex_normalize =pd.DataFrame(df_ex_normalize)\n",
    "df_ex_normalize.columns = X_ex.columns.tolist()\n",
    "\n",
    "X_ex = df_ex_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbadc812",
   "metadata": {
    "id": "fbadc812"
   },
   "outputs": [],
   "source": [
    "#miaim x , y ro be ham michaboonim ta betonim normilize konim\n",
    "\n",
    "arr_tain =X_train#.to_numpy()\n",
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_normalize = transform.fit_transform(arr_tain)\n",
    "df_normalize =pd.DataFrame(df_normalize)\n",
    "df_normalize.columns = X.columns.tolist()\n",
    "X_train = df_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23494689",
   "metadata": {
    "id": "23494689"
   },
   "outputs": [],
   "source": [
    "#miaim x , y ro be ham michaboonim ta betonim normilize konim\n",
    "\n",
    "arr =X_test#.to_numpy()\n",
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_test_normalize = transform.fit_transform(arr)\n",
    "df_test_normalize =pd.DataFrame(df_test_normalize)\n",
    "df_test_normalize.columns = X.columns.tolist()\n",
    "X_test =df_test_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a9e4a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.532e-01, tolerance: 8.537e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lasso_MO_ICU(X_train, y_train,X_test , X_ex):\n",
    "    # Perform feature selection using LASSO on the training set\n",
    "    \n",
    "    lasso = Lasso(alpha=0.0001)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the absolute coefficients and sort them\n",
    "    #absolute_coeffs = np.abs(lasso.coef_)\n",
    "    #sorted_indices = np.argsort(absolute_coeffs)[::-1]\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_ex = pd.DataFrame(X_ex)\n",
    "    # Select the top 2 features with the highest coefficients\n",
    "    #selected_feature_indices = sorted_indices[:40]\n",
    "    selected_feature_indices = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "    # Apply feature selection to both the training and test sets\n",
    "    X_train_selected_Mortality_ICU = X_train.iloc[:, selected_feature_indices]\n",
    "    X_test_selected_Mortality_ICU = X_test.iloc[:, selected_feature_indices]\n",
    "    X_ex = X_ex.iloc[:, selected_feature_indices]\n",
    "    return X_train_selected_Mortality_ICU ,X_test_selected_Mortality_ICU,X_ex\n",
    "\n",
    "X_train,X_test,X_ex = lasso_MO_ICU(X_train, y_train,X_test,X_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2106bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"y_train = y_train['Outcome_InhospitalMortality']\\ny_test= y_test['Outcome_InhospitalMortality']\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_train = y_train['Outcome_InhospitalMortality']\n",
    "y_test= y_test['Outcome_InhospitalMortality']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a60249dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X_train = X_train.drop(columns=['L1_BloodGroup_First'])\\nX_test =X_test.drop(columns=['L1_BloodGroup_First'])\\nX_ex =X_ex.drop(columns=['L1_BloodGroup_First'])\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_train = X_train.drop(columns=['L1_BloodGroup_First'])\n",
    "X_test =X_test.drop(columns=['L1_BloodGroup_First'])\n",
    "X_ex =X_ex.drop(columns=['L1_BloodGroup_First'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0e58d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks , RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "def balancing_dataset(X_train,y_train):\n",
    "    \n",
    "    tl = RandomUnderSampler()\n",
    "    X_resampled_train , y_resampled_train = tl.fit_resample(X_train,y_train)\n",
    "    X_resampled_test , y_resampled_test = tl.fit_resample(X_test,y_test)\n",
    "    \n",
    "    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test)\n",
    "a,b, X_test , y_test = balancing_dataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "add046c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = a,b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac69b28",
   "metadata": {
    "id": "6ac69b28"
   },
   "source": [
    ">>>Now dataset is cleaned and normalized "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fd4a0",
   "metadata": {},
   "source": [
    "## data selection Mortality and ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.linear_model import Lasso\\n\\ndef lasso_MO_ICU(X_train, y_train, X_test):\\n    # Perform feature selection using LASSO on the training set\\n    lasso = Lasso(alpha=0.1)\\n    lasso.fit(X_train, y_train)\\n\\n    # Get the absolute coefficients and sort them\\n    absolute_coeffs = np.abs(lasso.coef_)\\n    sorted_indices = np.argsort(absolute_coeffs>0)[::-1]\\n\\n    X_train = pd.DataFrame(X_train)\\n    X_test = pd.DataFrame(X_test)\\n\\n    # Select the top 2 features with the highest coefficients\\n    selected_feature_indices = sorted_indices[:40]\\n\\n    # Apply feature selection to both the training and test sets\\n    X_train_selected_Mortality_ICU = X_train.iloc[:, selected_feature_indices]\\n    X_test_selected_Mortality_ICU = X_test.iloc[:, selected_feature_indices]\\n\\n    return X_train_selected_Mortality_ICU, X_test_selected_Mortality_ICU\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.linear_model import Lasso\n",
    "\n",
    "def lasso_MO_ICU(X_train, y_train, X_test):\n",
    "    # Perform feature selection using LASSO on the training set\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    # Get the absolute coefficients and sort them\n",
    "    absolute_coeffs = np.abs(lasso.coef_)\n",
    "    sorted_indices = np.argsort(absolute_coeffs>0)[::-1]\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    # Select the top 2 features with the highest coefficients\n",
    "    selected_feature_indices = sorted_indices[:40]\n",
    "\n",
    "    # Apply feature selection to both the training and test sets\n",
    "    X_train_selected_Mortality_ICU = X_train.iloc[:, selected_feature_indices]\n",
    "    X_test_selected_Mortality_ICU = X_test.iloc[:, selected_feature_indices]\n",
    "\n",
    "    return X_train_selected_Mortality_ICU, X_test_selected_Mortality_ICU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675755c6",
   "metadata": {},
   "source": [
    "# Undersampling and and Oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c31ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.combine import SMOTETomek\\nfrom imblearn.under_sampling import TomekLinks\\nfrom imblearn.combine import SMOTEENN\\nfrom imblearn.ensemble import RUSBoostClassifier\\ndef balancing_dataset(X_train,y_train , X_test , y_test):\\n    \\n    tl = TomekLinks()\\n    X_resampled_train , y_resampled_train = tl.fit_resample(X_train,y_train)\\n    X_resampled_test , y_resampled_test = tl.fit_resample(X_test,y_test)\\n    \\n    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test )'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "def balancing_dataset(X_train,y_train , X_test , y_test):\n",
    "    \n",
    "    tl = TomekLinks()\n",
    "    X_resampled_train , y_resampled_train = tl.fit_resample(X_train,y_train)\n",
    "    X_resampled_test , y_resampled_test = tl.fit_resample(X_test,y_test)\n",
    "    \n",
    "    return (X_resampled_train, y_resampled_train,X_resampled_test , y_resampled_test )'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bfd27f",
   "metadata": {
    "id": "65bfd27f"
   },
   "source": [
    "# experimenting different models on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03126cba",
   "metadata": {
    "id": "03126cba"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8e654f8",
   "metadata": {
    "id": "d8e654f8"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f4e9e",
   "metadata": {
    "id": "249f4e9e"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9b8b780",
   "metadata": {
    "id": "a9b8b780"
   },
   "outputs": [],
   "source": [
    "\n",
    "#remember to consider x_test and y_test for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12beb341",
   "metadata": {
    "id": "12beb341"
   },
   "outputs": [],
   "source": [
    "#y_train_Outcome_InhospitalMortality = np.array(y_train['Outcome_InhospitalMortality'].tolist())\n",
    "#y_test_Outcome_InhospitalMortality = np.array(y_test['Outcome_InhospitalMortality'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a73cea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "def logistic_regression_classifier(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':42}\n",
    "\n",
    "\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "\n",
    "\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_predicted_Mortality_lr = best_classifier_lr.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_lr)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_lr)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_lr)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_lr)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_lr)\n",
    "\n",
    "\n",
    "    Logistic_Regression = {}\n",
    "    Logistic_Regression[\"accuracy\"] = accuracy\n",
    "    Logistic_Regression[\"precision\"] = precision\n",
    "    Logistic_Regression[\"recall\"] = recall\n",
    "    Logistic_Regression[\"specificity\"] = specificity\n",
    "    Logistic_Regression[\"f1\"] = f1\n",
    "    Logistic_Regression[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_lr)\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_lr\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_lr.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    Logistic_Regression[\"accuracy_ex\"] = accuracy\n",
    "    Logistic_Regression[\"precision_ex\"] = precision\n",
    "    Logistic_Regression[\"recall_ex\"] = recall\n",
    "    Logistic_Regression[\"specificity_ex\"] = specificity\n",
    "    Logistic_Regression[\"f1_ex\"] = f1\n",
    "    Logistic_Regression[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ff100",
   "metadata": {
    "id": "d43ff100"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77900b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_svm(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    svm_classifier = svm.SVC(random_state=42)\n",
    "\n",
    "\n",
    "    parameters_svm = {'random_state':42}\n",
    "\n",
    "\n",
    "    grid_search_svm = GridSearchCV(\n",
    "        estimator=svm_classifier,\n",
    "        param_grid=parameters_svm,\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "   \n",
    "    svm_cv = grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    " \n",
    "    best_classifier_svm = svm_cv.best_estimator_\n",
    "\n",
    "\n",
    "    y_predicted_Mortality_svm = best_classifier_svm.predict(X_test)\n",
    "\n",
    "   \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_svm)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_svm)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_svm)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_svm)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_svm)\n",
    "\n",
    "    svm_results = {}\n",
    "    svm_results[\"accuracy\"] = accuracy\n",
    "    svm_results[\"precision\"] = precision\n",
    "    svm_results[\"recall\"] = recall\n",
    "    svm_results[\"specificity\"] = specificity\n",
    "    svm_results[\"f1\"] = f1\n",
    "    svm_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_svm)\n",
    "\n",
    "  \n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_svm\n",
    "\n",
    "    y_predicted_Mortality_boost = best_classifier_svm.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    svm_results[\"accuracy_ex\"] = accuracy\n",
    "    svm_results[\"precision_ex\"] = precision\n",
    "    svm_results[\"recall_ex\"] = recall\n",
    "    svm_results[\"specificity_ex\"] = specificity\n",
    "    svm_results[\"f1_ex\"] = f1\n",
    "    svm_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] =y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    svm_results = (svm_results, y_plot)\n",
    "    \n",
    "    return svm_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848877b",
   "metadata": {
    "id": "2848877b"
   },
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "881b0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_tree(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_tree = {\"random_state\":42}\n",
    "\n",
    " \n",
    "    tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    " \n",
    "    grid_search_tree = GridSearchCV(\n",
    "        estimator=tree,\n",
    "        param_grid=parameters_tree,\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "\n",
    "    tree_cv = grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "  \n",
    "    best_classifier_tree = tree_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_predicted_Mortality_tree = best_classifier_tree.predict(X_test)\n",
    "\n",
    " \n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_tree)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_tree)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_tree)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_tree)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_tree)\n",
    "\n",
    "  \n",
    "    tree_results = {}\n",
    "    tree_results[\"accuracy\"] = accuracy\n",
    "    tree_results[\"precision\"] = precision\n",
    "    tree_results[\"recall\"] = recall\n",
    "    tree_results[\"specificity\"] = specificity\n",
    "    tree_results[\"f1\"] = f1\n",
    "    tree_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_tree)\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_tree\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_tree.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    tree_results[\"accuracy_ex\"] = accuracy\n",
    "    tree_results[\"precision_ex\"] = precision\n",
    "    tree_results[\"recall_ex\"] = recall\n",
    "    tree_results[\"specificity_ex\"] = specificity\n",
    "    tree_results[\"f1_ex\"] = f1\n",
    "    tree_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    tree_results = (tree_results, y_plot)\n",
    "    \n",
    "    return tree_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a4057",
   "metadata": {
    "id": "d15a4057"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e16b3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_knn = {'random_state':42}\n",
    "\n",
    " \n",
    "    knn = KNeighborsClassifier(random_state=42)\n",
    "\n",
    "\n",
    "    grid_search_knn = GridSearchCV(\n",
    "        estimator=knn,\n",
    "        param_grid=parameters_knn,\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "\n",
    "    knn_cv = grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "    best_classifier_knn = knn_cv.best_estimator_\n",
    "\n",
    "    y_predicted_Mortality_knn = best_classifier_knn.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_knn)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_knn)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_knn)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_knn)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_knn)\n",
    "\n",
    "    knn_results = {}\n",
    "    knn_results[\"accuracy\"] = accuracy\n",
    "    knn_results[\"precision\"] = precision\n",
    "    knn_results[\"recall\"] = recall\n",
    "    knn_results[\"specificity\"] = specificity\n",
    "    knn_results[\"f1\"] = f1\n",
    "    knn_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_knn)\n",
    "\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_knn\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_knn.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    knn_results[\"accuracy_ex\"] = accuracy\n",
    "    knn_results[\"precision_ex\"] = precision\n",
    "    knn_results[\"recall_ex\"] = recall\n",
    "    knn_results[\"specificity_ex\"] = specificity\n",
    "    knn_results[\"f1_ex\"] = f1\n",
    "    knn_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    knn_results = (knn_results, y_plot)\n",
    "    \n",
    "    return knn_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db56b9",
   "metadata": {
    "id": "a2db56b9"
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5139caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_forest(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "    parameters_forest = {'random_state':42}\n",
    "\n",
    "\n",
    "    forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "    grid_search_forest = GridSearchCV(\n",
    "        estimator=forest,\n",
    "        param_grid=parameters_forest,\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "\n",
    "    forest_cv = grid_search_forest.fit(X_train, y_train)\n",
    "\n",
    "    best_classifier_forest = forest_cv.best_estimator_\n",
    "\n",
    "    y_predicted_Mortality_forest = best_classifier_forest.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_forest)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_forest)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_forest)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_forest)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_forest)\n",
    "\n",
    "\n",
    "    forest_results = {}\n",
    "    forest_results[\"accuracy\"] = accuracy\n",
    "    forest_results[\"precision\"] = precision\n",
    "    forest_results[\"recall\"] = recall\n",
    "    forest_results[\"specificity\"] = specificity\n",
    "    forest_results[\"f1\"] = f1\n",
    "    forest_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_forest)\n",
    "\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_forest\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_forest.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    forest_results[\"accuracy_ex\"] = accuracy\n",
    "    forest_results[\"precision_ex\"] = precision\n",
    "    forest_results[\"recall_ex\"] = recall\n",
    "    forest_results[\"specificity_ex\"] = specificity\n",
    "    forest_results[\"f1_ex\"] = f1\n",
    "    forest_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    return forest_results, y_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cce87",
   "metadata": {
    "id": "873cce87"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5879d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_neural(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_neural = {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50)],  # You can adjust the architecture here\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001],\n",
    "        'max_iter': [200],\n",
    "        'random_state': [42],\n",
    "        'early_stopping': [True],\n",
    "        'validation_fraction': [0.1],\n",
    "        'n_iter_no_change': [10]\n",
    "    }\n",
    "\n",
    "\n",
    "    neural = MLPClassifier(random_state=42)\n",
    "\n",
    "    grid_search_neural = GridSearchCV(\n",
    "        estimator=neural,\n",
    "        param_grid=parameters_neural,\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "\n",
    "    neural_cv = grid_search_neural.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    best_classifier_neural = neural_cv.best_estimator_\n",
    "\n",
    "    \n",
    "    y_predicted_Mortality_neural = best_classifier_neural.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_neural)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_neural)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_neural)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_neural)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_neural)\n",
    "\n",
    " \n",
    "    neural_results = {}\n",
    "    neural_results[\"accuracy\"] = accuracy\n",
    "    neural_results[\"precision\"] = precision\n",
    "    neural_results[\"recall\"] = recall\n",
    "    neural_results[\"specificity\"] = specificity\n",
    "    neural_results[\"f1\"] = f1\n",
    "    neural_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_neural)\n",
    "\n",
    "    \n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test  \n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_neural\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_neural.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    neural_results[\"accuracy_ex\"] = accuracy\n",
    "    neural_results[\"precision_ex\"] = precision\n",
    "    neural_results[\"recall_ex\"] = recall\n",
    "    neural_results[\"specificity_ex\"] = specificity\n",
    "    neural_results[\"f1_ex\"] = f1\n",
    "    neural_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "   \n",
    "    y_plot[\"y_true_ex\"] =y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "\n",
    "    return neural_results, y_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jUZXKSEf50lK",
   "metadata": {
    "id": "jUZXKSEf50lK"
   },
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2715bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_boost(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "  \n",
    "    parameters_boost = {'random_state':42 }\n",
    "\n",
    " \n",
    "    boost = XGBClassifier(random_state=42)\n",
    "\n",
    "\n",
    "    grid_search_boost = GridSearchCV(\n",
    "        estimator=boost,\n",
    "        param_grid=parameters_boost,\n",
    "        cv=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "\n",
    "    boost_cv = grid_search_boost.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    best_classifier_boost = boost_cv.best_estimator_\n",
    "\n",
    "\n",
    "    y_predicted_Mortality_boost = best_classifier_boost.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_test, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_test, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_test, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_test, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    boost_results = {}\n",
    "    boost_results[\"accuracy\"] = accuracy\n",
    "    boost_results[\"precision\"] = precision\n",
    "    boost_results[\"recall\"] = recall\n",
    "    boost_results[\"specificity\"] = specificity\n",
    "    boost_results[\"f1\"] = f1\n",
    "    boost_results[\"AUC\"] = roc_auc_score(y_test, y_predicted_Mortality_boost)\n",
    "    y_plot = {}\n",
    "    y_plot[\"y_true\"] = y_test\n",
    "    y_plot[\"y_predicted\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    y_predicted_Mortality_boost = best_classifier_boost.predict(X_ex)\n",
    "    accuracy = accuracy_score(y_ex, y_predicted_Mortality_boost)\n",
    "    cm = confusion_matrix(y_ex, y_predicted_Mortality_boost)\n",
    "    precision = precision_score(y_ex, y_predicted_Mortality_boost)\n",
    "    recall = recall_score(y_ex, y_predicted_Mortality_boost)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    f1 = f1_score(y_ex, y_predicted_Mortality_boost)\n",
    "\n",
    "  \n",
    "    \n",
    "    boost_results[\"accuracy_ex\"] = accuracy\n",
    "    boost_results[\"precision_ex\"] = precision\n",
    "    boost_results[\"recall_ex\"] = recall\n",
    "    boost_results[\"specificity_ex\"] = specificity\n",
    "    boost_results[\"f1_ex\"] = f1\n",
    "    boost_results[\"AUC_ex\"] = roc_auc_score(y_ex, y_predicted_Mortality_boost)\n",
    "    y_plot[\"y_true_ex\"] = y_ex\n",
    "    y_plot[\"y_predicted_ex\"] = y_predicted_Mortality_boost\n",
    "    \n",
    "    return boost_results, y_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f251fc7",
   "metadata": {},
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b3f7bfa",
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_Outcome_InhospitalMortality=[]\n",
    "\n",
    "\n",
    "#X_train = df_normalize\n",
    "#y_train = df_before_normalize.loc[:,'Outcome_InhospitalMortality']\n",
    "#X_test = df_test_normalize\n",
    "#y_test = df_test_before_normalize.loc[:,'Outcome_InhospitalMortality']\n",
    "y_train_ = pd.DataFrame(y_train)\n",
    "y_test_ = pd.DataFrame(y_test)\n",
    "#X_train, X_test = lasso_MO_ICU(pd.DataFrame(X_train), y_train_ ,pd.DataFrame(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.to_excel(\"features after selection for LLM model.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "9       0.0\n",
       "13      0.0\n",
       "25      0.0\n",
       "49      0.0\n",
       "       ... \n",
       "17      1.0\n",
       "942     1.0\n",
       "388     1.0\n",
       "561     1.0\n",
       "2642    1.0\n",
       "Name: Outcome_InhospitalMortality, Length: 2132, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e12e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.array(y_train)\n",
    "y_test_ = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92362429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 75)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_ex_ = np.array(y_ex['Outcome_InhospitalMortality'].tolist())\n",
    "X_ex = np.array(X_ex)\n",
    "#y_train_ = np.array(y_train)\n",
    "#y_test_ = np.array(y_test)\n",
    "\n",
    "#X_train,y_train_ , X_test , y_test_ = balancing_dataset(X_train,y_train_ , X_test , y_test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1159adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ex_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b75f7abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GridSearchCV.__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m list_Outcome_InhospitalMortality\u001b[38;5;241m.\u001b[39mextend([\u001b[43mlogistic_regression_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_ex\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_ex_\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      2\u001b[0m                                             train_and_evaluate_svm(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n\u001b[0;32m      3\u001b[0m                                         train_and_evaluate_tree(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n\u001b[0;32m      4\u001b[0m                                         train_and_evaluate_knn(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n\u001b[0;32m      5\u001b[0m                                         train_and_evaluate_forest(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n\u001b[0;32m      6\u001b[0m                                         train_and_evaluate_neural(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n\u001b[0;32m      7\u001b[0m                                         train_and_evaluate_boost(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_)])\n\u001b[0;32m     10\u001b[0m result_dic_list_Outcome_InhospitalMortality \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtree\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneural\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboost\u001b[39m\u001b[38;5;124m'\u001b[39m], list_Outcome_InhospitalMortality))\n\u001b[0;32m     16\u001b[0m merged_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[31], line 17\u001b[0m, in \u001b[0;36mlogistic_regression_classifier\u001b[1;34m(X_train, y_train, X_test, y_test, X_ex, y_ex)\u001b[0m\n\u001b[0;32m     11\u001b[0m parameters_lr \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m42\u001b[39m}\n\u001b[0;32m     14\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m grid_search_lr \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m logreg_cv \u001b[38;5;241m=\u001b[39m grid_search_lr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     28\u001b[0m best_classifier_lr \u001b[38;5;241m=\u001b[39m logreg_cv\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[1;31mTypeError\u001b[0m: GridSearchCV.__init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "\n",
    "list_Outcome_InhospitalMortality.extend([logistic_regression_classifier(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_svm(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_tree(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_knn(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_forest(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_neural(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                        train_and_evaluate_boost(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_)])\n",
    "\n",
    "\n",
    "result_dic_list_Outcome_InhospitalMortality = dict(zip(['logistic_regression', 'svm', 'tree', 'knn', 'forest', 'neural', 'boost'], list_Outcome_InhospitalMortality))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged_dict = {}\n",
    "\n",
    "# List of dictionary names and their corresponding dictionaries\n",
    "dict_list = [('Outcome_InhospitalMortality', result_dic_list_Outcome_InhospitalMortality)]\n",
    "\n",
    "# Merge the dictionaries\n",
    "for name, result_dict in dict_list:\n",
    "    merged_dict[name] = result_dict\n",
    "\n",
    "# The merged_dict now contains all the dictionaries merged together\n",
    "\n",
    "\n",
    "df = pd.DataFrame(merged_dict)\n",
    "\n",
    "\n",
    "df = df.transpose()\n",
    "\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'Method'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for outcome, models in merged_dict.items():\n",
    "    for model, metrics in models.items():\n",
    "        accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex = metrics[0]['accuracy'], metrics[0]['precision'], metrics[0]['recall'], metrics[0]['specificity'], metrics[0]['f1'], metrics[0]['AUC'],metrics[0]['accuracy_ex'], metrics[0]['precision_ex'], metrics[0]['recall_ex'], metrics[0]['specificity_ex'], metrics[0]['f1_ex'], metrics[0]['AUC_ex']\n",
    "        y_true, y_predicted,y_true_ex,y_predicted_ex = metrics[1]['y_true'], metrics[1]['y_predicted'],metrics[1]['y_true_ex'], metrics[1]['y_predicted_ex']\n",
    "        data.append([outcome, model,accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex, y_true.tolist(), y_predicted.tolist(),y_true_ex.tolist(),y_predicted_ex.tolist()])\n",
    "\n",
    "columns = ['Outcome', 'Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1','AUC', 'Accuracy_ex', 'Precision_ex', 'Recall_ex', 'Specificity_ex', 'F1_ex','AUC_ex', 'y_true', 'y_predicted', 'y_true_ex', 'y_predicted_ex']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628316b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_ex</th>\n",
       "      <th>Precision_ex</th>\n",
       "      <th>Recall_ex</th>\n",
       "      <th>Specificity_ex</th>\n",
       "      <th>F1_ex</th>\n",
       "      <th>AUC_ex</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_predicted</th>\n",
       "      <th>y_true_ex</th>\n",
       "      <th>y_predicted_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.723769</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.721627</td>\n",
       "      <td>0.725910</td>\n",
       "      <td>0.723176</td>\n",
       "      <td>0.723769</td>\n",
       "      <td>0.722498</td>\n",
       "      <td>0.908584</td>\n",
       "      <td>0.725089</td>\n",
       "      <td>0.712281</td>\n",
       "      <td>0.806531</td>\n",
       "      <td>0.718685</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.744111</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.700214</td>\n",
       "      <td>0.788009</td>\n",
       "      <td>0.732363</td>\n",
       "      <td>0.744111</td>\n",
       "      <td>0.697658</td>\n",
       "      <td>0.917464</td>\n",
       "      <td>0.682384</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.782653</td>\n",
       "      <td>0.720140</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>tree</td>\n",
       "      <td>0.569593</td>\n",
       "      <td>0.562141</td>\n",
       "      <td>0.629550</td>\n",
       "      <td>0.509636</td>\n",
       "      <td>0.593939</td>\n",
       "      <td>0.569593</td>\n",
       "      <td>0.511001</td>\n",
       "      <td>0.790387</td>\n",
       "      <td>0.526690</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.632141</td>\n",
       "      <td>0.487907</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.672377</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.749465</td>\n",
       "      <td>0.595289</td>\n",
       "      <td>0.695825</td>\n",
       "      <td>0.672377</td>\n",
       "      <td>0.691980</td>\n",
       "      <td>0.869379</td>\n",
       "      <td>0.722420</td>\n",
       "      <td>0.571930</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.647175</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>forest</td>\n",
       "      <td>0.766595</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.700214</td>\n",
       "      <td>0.832976</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.766595</td>\n",
       "      <td>0.680625</td>\n",
       "      <td>0.921250</td>\n",
       "      <td>0.655694</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.766112</td>\n",
       "      <td>0.717321</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>neural</td>\n",
       "      <td>0.744111</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.728051</td>\n",
       "      <td>0.760171</td>\n",
       "      <td>0.739935</td>\n",
       "      <td>0.744111</td>\n",
       "      <td>0.702626</td>\n",
       "      <td>0.905639</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>0.712281</td>\n",
       "      <td>0.789764</td>\n",
       "      <td>0.706229</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>boost</td>\n",
       "      <td>0.760171</td>\n",
       "      <td>0.752599</td>\n",
       "      <td>0.775161</td>\n",
       "      <td>0.745182</td>\n",
       "      <td>0.763713</td>\n",
       "      <td>0.760171</td>\n",
       "      <td>0.723918</td>\n",
       "      <td>0.889714</td>\n",
       "      <td>0.746441</td>\n",
       "      <td>0.635088</td>\n",
       "      <td>0.811805</td>\n",
       "      <td>0.690765</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Outcome                Model  Accuracy  Precision  \\\n",
       "0  Outcome_InhospitalMortality  logistic_regression  0.723769   0.724731   \n",
       "1  Outcome_InhospitalMortality                  svm  0.744111   0.767606   \n",
       "2  Outcome_InhospitalMortality                 tree  0.569593   0.562141   \n",
       "3  Outcome_InhospitalMortality                  knn  0.672377   0.649351   \n",
       "4  Outcome_InhospitalMortality               forest  0.766595   0.807407   \n",
       "5  Outcome_InhospitalMortality               neural  0.744111   0.752212   \n",
       "6  Outcome_InhospitalMortality                boost  0.760171   0.752599   \n",
       "\n",
       "     Recall  Specificity        F1       AUC  Accuracy_ex  Precision_ex  \\\n",
       "0  0.721627     0.725910  0.723176  0.723769     0.722498      0.908584   \n",
       "1  0.700214     0.788009  0.732363  0.744111     0.697658      0.917464   \n",
       "2  0.629550     0.509636  0.593939  0.569593     0.511001      0.790387   \n",
       "3  0.749465     0.595289  0.695825  0.672377     0.691980      0.869379   \n",
       "4  0.700214     0.832976  0.750000  0.766595     0.680625      0.921250   \n",
       "5  0.728051     0.760171  0.739935  0.744111     0.702626      0.905639   \n",
       "6  0.775161     0.745182  0.763713  0.760171     0.723918      0.889714   \n",
       "\n",
       "   Recall_ex  Specificity_ex     F1_ex    AUC_ex  \\\n",
       "0   0.725089        0.712281  0.806531  0.718685   \n",
       "1   0.682384        0.757895  0.782653  0.720140   \n",
       "2   0.526690        0.449123  0.632141  0.487907   \n",
       "3   0.722420        0.571930  0.789116  0.647175   \n",
       "4   0.655694        0.778947  0.766112  0.717321   \n",
       "5   0.700178        0.712281  0.789764  0.706229   \n",
       "6   0.746441        0.635088  0.811805  0.690765   \n",
       "\n",
       "                                              y_true  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         y_predicted  \\\n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "5  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "6  [0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, ...   \n",
       "\n",
       "                                           y_true_ex  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                      y_predicted_ex  \n",
       "0  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, ...  \n",
       "1  [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "2  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "3  [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, ...  \n",
       "4  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...  \n",
       "5  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "6  [1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, ...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel('Experiment_1_ML_results_final.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.341px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
