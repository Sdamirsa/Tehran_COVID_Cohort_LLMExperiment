{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b129d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel(\"3.xlsx\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ooutcome columns: 1.are Outcome_InhospitalMortality 2.TM_S_Intubation  3.Outcome_ICUadmission  4.TM_S_Dialysis\n",
    "df = df.dropna(subset=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "\n",
    "#inja oomadim va external validation ro freeze kardim\n",
    "df_internal_validation = df[df['Patient_Hospital']!=\"Hospital2\"]\n",
    "df_external_validation = df[df['Patient_Hospital']==\"Hospital2\"]\n",
    "df_internal_validation = df_internal_validation.drop(columns=['Patient_Hospital'])\n",
    "df_external_validation = df_external_validation.drop(columns=['Patient_Hospital'])\n",
    "\n",
    "#df.to_excel(\"excluding NAN.xlsx\", index=False)\n",
    "\n",
    "#inja train test split kardim va target variable ro jodakardim\n",
    "# Define features (X) and target variable (y)\n",
    "X = df_internal_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y  = df_internal_validation[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "# Perform the train-test split (adjust the test_size as needed)\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size = 0.2 , random_state = 42)\n",
    "\n",
    "\n",
    "#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\n",
    "cat_col=[]\n",
    "num_col=[]\n",
    "for i in range(len(X_train.columns)):\n",
    "    if i <=52:\n",
    "        cat_col.append(X_train.columns[i])\n",
    "    else:\n",
    "        num_col.append(X_train.columns[i])\n",
    "    \n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "X_train_array  =X_train.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed = imputer.fit_transform(X_train_array)\n",
    "\n",
    "df_imputed = pd.DataFrame(imputed)\n",
    "df_imputed.columns=pd.DataFrame(X_train).columns.tolist()\n",
    "\n",
    "\n",
    "df_imputed\n",
    "\n",
    "for i in cat_col:\n",
    "    df_imputed[[i]] = df_imputed[[i]].round()\n",
    "\n",
    "df_imputed.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#miaim x , y ro be ham michaboonim ta betonim normilize konim\n",
    "df_before_normalize = pd.concat([df_imputed , y_train], axis=1)\n",
    "\n",
    "df_before_normalize.shape\n",
    "\n",
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_normalize = transform.fit_transform(df_before_normalize)\n",
    "df_normalize =pd.DataFrame(df_normalize)\n",
    "df_normalize.columns = df_internal_validation.columns.tolist()\n",
    "\n",
    "X_train = df_before_normalize.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_train = df_before_normalize[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "\n",
    "\n",
    "#inja miaim va data haye categorical va numerical ro moshakhas mikonim ke bade knn categorical ha ro round konim\n",
    "cat_col=[]\n",
    "num_col=[]\n",
    "for i in range(len(X_test.columns)):\n",
    "    if i <=52:\n",
    "        cat_col.append(X_test.columns[i])\n",
    "    else:\n",
    "        num_col.append(X_test.columns[i])\n",
    "    \n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "X_test_array  =X_test.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed_test = imputer.fit_transform(X_test_array)\n",
    "\n",
    "df_imputed_test = pd.DataFrame(imputed_test)\n",
    "df_imputed_test.columns=pd.DataFrame(X_test).columns.tolist()\n",
    "\n",
    "\n",
    "df_imputed_test\n",
    "\n",
    "for i in cat_col:\n",
    "    df_imputed_test[[i]] = df_imputed_test[[i]].round()\n",
    "\n",
    "df_imputed_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_imputed_test.shape\n",
    "\n",
    "y_test.shape\n",
    "\n",
    "#miaim x , y ro be ham michaboonim ta betonim normilize konim\n",
    "df_test_before_normalize = pd.concat([df_imputed_test , y_test], axis=1)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "transform = preprocessing.StandardScaler()\n",
    "df_test_normalize = transform.fit_transform(df_test_before_normalize)\n",
    "df_test_normalize =pd.DataFrame(df_test_normalize)\n",
    "df_test_normalize.columns = df_internal_validation.columns.tolist()\n",
    "\n",
    "X_test = df_test_before_normalize.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_test = df_test_before_normalize[['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79217edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
